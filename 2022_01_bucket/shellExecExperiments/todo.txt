The "at" command may solve one of the problems.
As for the original debugging problem, perhaps the solution is to do 
kw_php_shell_exec();
This may work with an interface that demands the within-calling-PHP-memory-space version.  If the 
idea is to keep from tripping on PHP when debugging PHP, then write the called scripts such that they can 
easily be called as functions and methods rather than a shell script.

***********
have script either demand starting a server separately or else 
start the server once and demand rerunning
Need a pid file that is not a FIFO
***********
shell_exec(__FILE__ . ' exec ' . $h . ' > /dev/null 2>&1 &');

		$f = '/dev/null';
		$pc = $c . ' > ' . $f . ' 2>&1 & echo $! ';
		$pid = trim(shell_exec($pc));
		
		$tc = "tail -f --pid=$pid /dev/null";
		echo($tc);
		shell_exec($tc);

***
probably a lock file for my own sem_lock()
-- actually, no.  The point of this exercise is to debug one thing at a time.  Locking using __FILE__ is fine.
******
But on a Unix system there are lots of jobs which run independently for long periods of time. They achieve this by:

1) they are first started, say as pid 1234, and try to fork, say to pid 1235 after calling fork, pid 1234 exits
2) pid 1235 will become the daemon - it closes all its open fds including those for stdin, stdout and stderr
3) pid 1235 now calls setsid(), this dissociates this process from the tree of processes which led to its creation (and typically makes it a child of the 'init' process).

You can do all this in a PHP script, assuming you've got the posix and pcntl extensions. However in my experience its usually a lot simpler to ask an existing daemon to run the script for you:


print `echo /usr/bin/php -q longThing.php | at now`;

http://symcbean.blogspot.com/2010/02/php-and-long-running-processes.html
